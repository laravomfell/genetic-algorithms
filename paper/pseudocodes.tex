\section{Pseudo Codes}
\label{append}
In this part, pseudo code for the used algorithms is provided. Due to sometimes lengthy implementation of the used evolutionary algorithms, pseudo code is provided to convey the procedure of each algorithm instead of individuals operations. Every algorithm takes inputs, some are identical across all algorithms like the used fitness function (the Brier Score in our case), the population size Psize, the problem dimension, the generations/the iterations the algorithm should run and the boundaries of the search space (low, up). Additionally, some are algorithm-specific and provided in the header of each code section. The pseudo code is adapted to the present optimization problem, such that each code includes a "Normalization" section, where invalid solutions are reconfined to the boundaries of the search. As explained in Section \ref{introEA}, the normalization function is defined as follows:

\begin{algorithm}
\singlespacing
\caption{Normalization Function} \label{NORM}
\begin{algorithmic}[1]
	\Function{Normalize}{P}
	\State P $\gets \: \mid \text{P} \mid$    \Comment{no negative values}
	\For {$i \gets$ 1, Psize}
		\State P$_i \gets$ P$_i / \text{sum(P}_i)$ \Comment{normalize weights to 1}
	\EndFor	
	\EndFunction
\end{algorithmic}
\end{algorithm}

\newpage
\subsection{Genetic Algorithm}

\begin{algorithm}
\singlespacing
\caption{Genetic Algorithm} \label{GA}
\begin{algorithmic}[1]
	\INPUT fit.func, Psize, dim, generations, low, up, elite, p.cross, p.mut
	\OUTPUT globalminimizer
	
	\noindent \Statex \hrulefill
	\Statex \textbf{\# Initialization}
	\For {$ i \gets$ 1, Psize} 
	\State $P_i \gets $ random solution vector$_{(1 \times dim)} \sim [low, up] $
	\State fitness$_i \gets $ fit.func(P$_i)$ \EndFor
	\Statex
	
	\For {$k \gets $1, generations}
	\State elites $\gets$ select the elite-many best performing solutions
	\Statex \textbf{\# Roulette-Wheel Selection}
	\State wheel $\gets$ fitness / sum(fitness)
	\State selection $\gets$ sample Psize-many vectors from P with probability = wheel
	\State P $\gets$ selection
	
	\Statex \textbf{\# Crossover}
	
	\For {$j \gets $ 1, Psize/2}
	\If {p.cross $>$ \textit{rndn}}
	\State parent1 $\gets$ sample vector from P
	\State parent2 $\gets$ sample vector from P
	\State offspring1 $\gets$ crossover of (parent1$_{[1:crosspoint]}$, parent2$_{[crosspoint+1:D]})$
	\State offspring2 $\gets$ crossover of (parent2$_{[1:crosspoint]}$, parent1$_{[crosspoint+1:D]})$ \EndIf 
	
	\Statex {$\qquad \quad  \textbf{\# Mutation}$}
	\If {p.mut $>$ \textit{rndn}}
	\State offspring $ \gets$ perform mutation \EndIf
	\State P $\gets$ replace parents by offspring
	\EndFor
	
	\Statex \textbf{\# Boundary Control}
	\State P $\gets$ normalize(P)

	
	\Statex \textbf{\# Elite Evaluation}
	\State fitness $\gets$ fit.func(P) 
	\State P $\gets$ replace the elite-many worst performing solutions by \textit{elites}
	
	\State fitness $\gets$ fit.func(P)
	\State globalminimizer $\gets$ best evaluation of P in fitness
	\EndFor

\end{algorithmic}
\end{algorithm}

%\newpage
\subsection{Backtracking Search Algorithm}
\begin{algorithm}
	\singlespacing
	\caption{Backtracking Search Algorithm} \label{BSA}
	\begin{algorithmic}[1]
		\INPUT fit.func, Psize, dim, generations, low, up, mixrate
		\OUTPUT globalminimizer
		
		\noindent \Statex  \hrulefill
		\Statex \textbf{\# Initialization}
		\For {$ i \gets$ 1, Psize} 
		\State $P_i \gets $ random solution vector$_{(1 \times dim)} \sim [low, up] $
		\State fitness$_i \gets $ fit.func(P$_i)$ \EndFor
		\Statex
		
		\For {$k \leftarrow$ 1, generations}
		\Statex \textbf{\# Selection I}
		\If {$a < b \: | \: a, b \sim U(0,1)$}
		\State {histP $\gets$ P} \EndIf
		\State histP $\gets$ permuting(histP)
		\Statex \textbf{\# Mutation}
		\State mutant $\gets$ P $ + \:3 \cdot rndn$(histP $-$ P)
		\Statex \textbf{\# Crossover}
		\State map$_{(Psize\times dim)} \gets 0$
		\For {$i \gets$ 1, Psize} 				\Comment{two predefined strategies of BSA} 
		\If {$c < d \: | \: c, d \sim U(0, 1)$}
		\State map$_{i, u} = 1$ 		\Comment{where $u = mixrate \cdot dim \cdot rndn$} 
		\Else
		\State map$_{i, rndn} = 1$      
		\EndIf
		\EndFor
		
		\For{$i \gets$ 1, Psize; $j \gets$ 1, dim}    
		\If {map$_{i, j} = 0$} 
		\State mutant$_{i,j} \gets$ P$_{i, j}$ \EndIf 
		\EndFor 
		
		\Statex \textbf{\# Boundary Control}
		\State P $\gets$ normalize(P) 
		\Statex \textbf{\# Selection II}
		\State fitness.mutant $\gets$ fit.func(mutant)
		\For {$i \gets$ 1, Psize}
		\If {fitness.mutant$_i <$ fitness$_i$}
		\State P$_i \gets$ mutant$_i$
		\EndIf
		\EndFor
		\State fitness $\gets$ fit.func(P)
		\State globalminimizer $\gets$ best evaluation of P in fitness
		
		\EndFor	
		
	\end{algorithmic}
\end{algorithm}

\newpage
\subsection{Population-based Incremental Learning}
\begin{algorithm}
	\singlespacing
	\caption{Interval-based PBIL} \label{PBIL}
	\begin{algorithmic}[1]
		\INPUT fit.func, Psize, dim, generations, low, up, $\gamma$, $\beta$, mutShift
		\OUTPUT globalminimizer
		
		\noindent \Statex \hrulefill
		\Statex \textbf{\# Initialization}
		\For {$i \gets $ 1, Psize}
		\State interval$_i \gets (low_i + up_i)/dim$ \Comment{see last paragraph}
		\State pvec$_i$ $\gets 0.5$
		\State P$_i$ $\gets$ draw solution vector$_{(1\times dim)}$ according to pvec$_i$
		\State fitness$_i \gets$ fit.func(P$_i$)
		\EndFor
		
		\Statex
		\For {$k \gets$ 1, generations}
		\State globalminimizer $\gets$ best evaluation of P in fitness
		\State pvec $\gets$ pvec $\cdot \: (1-\gamma) + \gamma \: \cdot \:$globalminimizer
		
		\For {$i \gets$ 1, pvec}
		\If {$a < \beta \: | \: a \sim U(0,1)$} 
		\State pvec$_i \gets$ pvec$_i \cdot (1-\textit{mutShift}) + \textit{rndn.integer}(0,1) \cdot \textit{mutShift}$
		\EndIf
		
		\If {pvec$_i \leq 0.1$}
		\State up$_i \gets (low_i + up_i)/dim$
		\State interval$_i \gets (low_i + up_i)/dim$
		\State pvec$_i \gets$ 0.5
		\ElsIf {pvec$_i \geq 0.9$}
		\State low$_i \gets (low_i + up_i)/dim $
		\State interval$_i \gets (low_i + up_i)/dim$
		\State pvec$_i$ $\gets 0.5$ \EndIf
		\EndFor
		%\State globalminimizer $\gets$ best
		\EndFor
		
	\end{algorithmic}
\end{algorithm}

\newpage
\subsection{Particle Swarm Optimization}
\begin{algorithm}
	\singlespacing
	\caption{PSO} \label{PSO}
	\begin{algorithmic}[1]
		\INPUT fit.func, Psize, dim, generations, low, up, phi, gamma
		\OUTPUT globalminimizer
		
		\noindent \Statex \hrulefill
		\Statex \textbf{\# Initialization}
		\State phi$_1 \gets$ phi$_2 \gets $phi
		
		\For {$ i \gets$ 1, Psize} 
		\State P$_i \gets $ random solution vector$_{(1 \times dim)} \sim$ [low, up] 
		\State fitness$_i \gets$ fit.func(P$_i$)
		\State pbest$_i \gets P_i$ \Comment{Particle $i$'s best solution}
		\State nbest$_i \gets$ min(fitness$_{n_i}$) \Comment{Best solution in particle $i$'s neighborhood}
		\State velocities$_i \gets rndn(0, 0.2)$
		\EndFor
		\Statex
		
		\For {$k \gets$ 1, generations} 
		\For {$i \gets$ 1, Psize}
		\State \parbox[t]{\dimexpr\linewidth-\algorithmicindent}{ velocities$_i \gets$ gamma $\cdot$ velocities$_i + $phi$_1 \vec{U}[0,1]$ (pbest$_i -$ P$_i) +$ phi$_2 \vec{U}[0,1]$ (nbest$_i -$ P$_i$)\strut} % check later
		\State P$_i \gets$ P$_i +$ velocities$_i$
		\EndFor
		\Statex \textbf{\# Boundary Control} 
		\State P $\gets$ normalize(P)
		
		\Statex \textbf{\# Update best}
		\State fitness $\gets$ fit.func(P)
		\If {min(fitness$_{n_i}) < $nbest$_i$}
		\State nbest$_i := $ min(fitness$_{n_i}$) \EndIf
		\If {min(fitness$_i) <$ pbest$_i$}
		\State pbest$_i :=$ min(fitness$_i$) \EndIf
		
		\State globalminimizer $\gets$ best evaluation of P in fitness
		
		\EndFor
		
\end{algorithmic}
\end{algorithm}