\section{Conclusion}
\label{conc}
The results obtained by the EAs in the four experiments on the DMC data are very much promising and show that they are able to find good solutions with respect to Ensemble Selection. Throughout the experiments, there is no clear winner with the bagged genetic algorithm with a small population size, the bagged and unbagged BSA with a large population and the binary PBIL yielding strong solutions that even outperform the single best classifier on the classification data. 

Given more time and more computational capacities, one could possible improve the performance of the tested algorithms even further as the comparative results show room for further investigation: 
Regarding the promising results of the PSO, the implementation of even more information topologies as suggested by \cite{kennedymendes} could further improve them. Also, some of the slow convergence of the PSO could be attributed to the use of the random inertia weight as proposed by \cite{bansal2011inertia} so systematic testing of different weights might prove useful. 

Regarding the three question raised at the end of Section \ref{subop}, a) overfitting was not an issue in this setup so that b) cannot be answered. For c) the effect of bagging is not entirely straightforward in the application on the DMC data. For all algorithms tested, some configurations produce better results with bagging, some without. The effect of the number of bags on the performance could be further studied.

Still, the results of this study should not be overestimated. The surprisingly good performance of the sets on the classification data is not necessarily indicative of their ability to find the best ensemble. All EAs did not perform convincingly on the training data which they could fit to and were easily outperformed by other heuristic methods like Hill-Climbing and Stochastic Hill-Climbing. Using Cross Validation or more data subsamples could elucidate this issue.

Still, one has to carefully weigh the pros and cons of investing in optimizing and tuning an evolutionary algorithm instead of sticking with a simple-to-implement method that compares in performance. Based on our results, we recommend the latter.