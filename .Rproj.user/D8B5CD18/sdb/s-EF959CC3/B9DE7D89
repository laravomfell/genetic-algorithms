{
    "collab_server" : "",
    "contents" : "##############################################\n#                                            #\n#  1. FUNCTION FOR CHECKING NEW DATA LEVELS  #\n#                                            #\n##############################################\n\n# 1. The function compares factor levels, which are present in training and validation data.\n# \n# 2. If there are new values in \"test\" subset, which are not present in \"train\" subset, the function \n#    returns the list of these levels. The function does not check if there are values, which are present \n#    in training subset only, since that does not prevent prediction algorithms from working.\n\n# introducing the function\ncheck.data <- function(train, test) {\n  \n  # creating necessary objects\n  factors <- rep(FALSE, ncol(train))\n  levels  <- array(vector(mode = \"list\", length = 1), c(1, ncol(train)))\n  \n  # checking for new factor levels\n  for(attr in colnames(train)) {\n    if (is.factor(train[[attr]])) {\n      \n      # comparing levels\n      index <- unique(test[[attr]]) %in% unique(train[[attr]])\n      new.levels <- unique(test[[attr]])[!index]\n      \n      # displaying information\n      if (length(new.levels) != 0 & length(new.levels) < 5) {\n        print(c(paste0(attr, \" - \", length(new.levels), \" new levels:\"), paste(as.character(new.levels), collapse = \", \")))\n        factors[which(colnames(train) == attr)] <- TRUE\n        levels[[1, which(colnames(train) == attr)]] <- new.levels\n      }\n      if (length(new.levels) != 0 & length(new.levels) >= 5) {\n        print(c(paste0(attr, \" - \", length(new.levels), \" new levels, including:\"), paste(as.character(new.levels[1:5]), collapse = \", \")))\n        factors[which(colnames(train) == attr)] <- TRUE\n        levels[[1, which(colnames(train) == attr)]] <- new.levels\n      }\n      if (length(new.levels) == 0) {\n        print(paste0(attr, \" - no new levels\"))\n      }\n    }\n  }\n  \n  # returning variables\n  print(\"Partitioning is complete.\")\n  return(list(factors = factors, levels = levels))\n}\n\n\n#############################################\n#                                           #\n#   2. FUNCTION FOR PREPARING PREDICTIONS   #\n#                                           #\n#############################################\n\n# 1. The function works with numeric predictions from both regression and classifiation models.\n#  \n# 2. The function preprocesses vector with predictions and accounts for several data anomalies:\n#   - predictions are rounded to the nearest integer\n#   - negative predictions are set to 0\n#   - too large predictions are set to 5\n#   - if predicted returnQuantity > quantity, then prediction = quantity\n#   - if quantity = 0, then prediction = 0\n#   - if productGroup = Gift Card, then prediction = 0\n#\n# 3. If model is a binary classifier, it is possible to set a cutoff for prediction rounding.\n#    In that case, input vector should contain probabilities of \"1\" (returning the product).\n\n# introducing the function\nprepare.prediction <- function(prediction, test.data, cutoff = 0.5) {\n  \n  # displaying errors\n  if (is.vector(prediction)      == FALSE)   {stop(\"Predctions have to be a vector\")}\n  if (is.numeric(prediction)     == FALSE)   {stop(\"Predctions have to be numeric\")}\n  if (length(prediction) != nrow(test.data)) {stop(\"Predctions and data are not the same length\")}\n  \n  # rounding predictions\n  if (cutoff == 0.5) {\n    prediction <- round(prediction, digits = 0)\n  }\n  else {\n    prediction[prediction >= cutoff] <- 1\n    prediction[prediction <  cutoff] <- 0\n  }\n  \n  # eliminating extreme values\n  prediction[prediction < 0] <- 0\n  prediction[prediction > 5] <- 5\n  \n  # checking if returnQuantity > quantity\n  prediction[prediction > test.data$quantity] <- test.data$quantity[prediction > test.data$quantity]\n  \n  # imputing zeros for giftcards\n  prediction[test.data$productGroup == \"GC\"] <- 0\n  \n  # imputing zeros for quantity = 0\n  prediction[test.data$quantity == 0] <- 0 \n  \n  # returning predictions\n  return(prediction)\n}\n\n\n\n#############################################\n#                                           #\n#     3. FUNCTION FOR ERROR EVALUATION      #\n#                                           #\n#############################################\n\n# 1. The function returns two error measures: total.error, which is the error function used in competition,\n#    and mean.error, which is total.error divided by the number of observations in the testing data.\n#\n# 2. If predictions are not integers, they are automatically rounded to the nearest integer, \n#    since only natural numbers and zeros are allowed as predictions in the submission file.\n\n# introducing the function\nprediction.error <- function(prediction, test.data) {\n  \n  # displaying errors\n  if (is.vector(prediction)      == FALSE)    {stop(\"Predctions have to be a vector\")}\n  if (is.numeric(prediction)     == FALSE)    {stop(\"Predctions have to be numeric\")}\n  if (length(prediction) != nrow(test.data))  {stop(\"Predctions and data are not the same length\")}\n  \n  # rounding prediction to the integers\n  if (identical(prediction, round(prediction)) == FALSE) {warning(\"Predictions are not integers. The values are automatically rounded.\")}\n  prediction <- round(prediction, digits = 0)\n  \n  # calculating errors\n  actuals     <- test.data$returnQuantity\n  total.error <- sum(abs(prediction - actuals))\n  mean.error  <- total.error/nrow(test.data)\n  \n  # returning errors\n  return(list(total.error = total.error, mean.error = mean.error))\n}\n\n\n\n#############################################\n#                                           #\n#   4. FUNCTION FOR EXPORTING PREDICTIONS   #\n#                                           #\n#############################################\n\n# 1. The function untrims relevant ID variables since they have to be present in submission \n#    dataset in their initial format. If we make additional changes to these variables, they\n#    have to be accounted for in the function.\n#\n# 2. If predictions are not integers, they are automatically rounded to the nearest integer, \n#    since only natural numbers and zeros are allowed as predictions in the submission file.\n\n# introducing the function\nsave.prediction <- function(prediction, test.data, file.name = \"humboldt\") {\n  \n  # displaying error messages\n  if (is.vector(prediction)    == FALSE)     {stop(\"Predctions have to be a vector\")}\n  if (is.numeric(prediction)   == FALSE)     {stop(\"Predctions have to be numeric\")}\n  if (length(prediction) != nrow(test.data)) {stop(\"Predictions and dataset are not the same length\")}\n  \n  # creadting dataset with relevant coloumns\n  test.data <- test.data[, c(\"orderID\", \"articleID\", \"colorCode\", \"sizeCode\")]\n  \n  # untrimming ID variables\n  test.data <- within(test.data, {\n    orderID    <- as.character(paste0(\"a\", as.character(orderID)))\n    articleID  <- as.character(paste0(\"i100\", as.character(articleID)))\n  })\n  \n  # rounding predictions\n  if (identical(prediction, round(prediction)) == FALSE) {warning(\"Predictions are not integers. The values are automatically rounded.\")}\n  prediction <- round(prediction, digits = 0)\n  \n  # adding predictions to the data\n  test.data$prediction <- prediction\n  \n  # exporting predictions\n  file.name <- paste(file.name, \".txt\", sep = \"\")\n  write.table(test.data, row.names = FALSE, col.names = TRUE, quote = FALSE, sep = \";\", file = file.name)\n}\n\n\n#############################################\n#                                           #\n#    5. FUNCTION TO IMPUTE RETURN RATES     #\n#                                           #\n#############################################\n\n# introducing the function\nadd_returns <- function(train, test, standard_value = 0.5) {\n  \n  # transforming data\n  train <- data.table(train)\n  test  <- data.table(test)\n  \n  # calculating return rates\n  train$return_per_color <- return_per_color(train)\n  train$return_per_size <- return_per_size(train)\n  train$return_per_productGroup <- return_per_productGroup(train)\n  train$return_per_voucherID <- return_per_voucherID(train)\n  train$return_per_paymentMethod <- return_per_paymentMethod(train)\n  train$return_per_customerID <- return_per_customerID(train)\n  \n  # writing to test subcet\n  test <- merge(test,unique(train[,.(return_per_color),by=colorCode]), by=\"colorCode\",all.x = TRUE)\n  test <- merge(test,unique(train[,.(return_per_size),by=sizeCode]), by=\"sizeCode\",all.x = TRUE)\n  test <- merge(test,unique(train[,.(return_per_productGroup),by=productGroup]), by=\"productGroup\",all.x = TRUE)\n  test <- merge(test,unique(train[,.(return_per_voucherID),by=voucherID]), by=\"voucherID\",all.x = TRUE)\n  test <- merge(test,unique(train[,.(return_per_paymentMethod),by=paymentMethod]), by=\"paymentMethod\",all.x = TRUE)\n  test <- merge(test,unique(train[,.(return_per_customerID),by=customerID]), by=\"customerID\",all.x = TRUE)\n  \n  # imputing missing values\n  test[,return_per_color := replace(return_per_color,is.na(return_per_color),standard_value)]\n  test[,return_per_size := replace(return_per_size,is.na(return_per_size),standard_value)]\n  test[,return_per_productGroup := replace(return_per_productGroup,is.na(return_per_productGroup),standard_value)]\n  test[,return_per_voucherID := replace(return_per_voucherID,is.na(return_per_voucherID),standard_value)]\n  test[,return_per_paymentMethod := replace(return_per_paymentMethod,is.na(return_per_paymentMethod),standard_value)]\n  test[,return_per_customerID := replace(return_per_customerID,is.na(return_per_customerID),standard_value)]\n  \n  ## imputation for customerID: average return of new customer\n  returning_customers <- duplicated(test$customerID)\n  newCustomer_return <- test[!returning_customers, mean(returnQuantity, na.rm=TRUE)]\n  test[,return_per_customerID := replace(return_per_customerID,is.na(return_per_customerID),newCustomer_return)]\n  \n  # transforming data\n  train <- as.data.frame(train)\n  test  <- as.data.frame(test)\n  \n  # saving data\n  return(list(train = train, test = test))\n}\n\n\n#############################################\n#                                           #\n#  6. SPECIFIC FUNCTIONS FOR RETURN RATES   #\n#                                           #\n#############################################\n\n# rerurn per voucherID\nreturn_per_voucherID <- function(dt){\n  dt[, new := mean(returnQuantity,na.rm=TRUE), by = voucherID]\n  dt[is.na(dt$new)]$new <- 0.5\n  return(dt$new)\n}\n\n# rerurn per size\nreturn_per_size <- function(dt){\n  dt[, new := mean(returnQuantity,na.rm=TRUE), by = sizeCode]\n  dt[is.na(dt$new)]$new <- 0.5\n  return(dt$new)\n}\n\n# return per productGroup\nreturn_per_productGroup <- function(dt){\n  dt[, new := mean(returnQuantity,na.rm=TRUE), by = productGroup]\n  dt[is.na(dt$new)]$new <- 0.5\n  return(dt$new)\n}\n\n# return per customerID\nreturn_per_customerID <- function(dt){\n  dt[, new := mean(returnQuantity,na.rm=TRUE), by = customerID]\n  dt[is.na(dt$new)]$new <- 0.5\n  return(dt$new)\n}\n\n# return per paymentMethod\nreturn_per_paymentMethod <- function(dt){\n  dt[, new := mean(returnQuantity,na.rm=TRUE), by = paymentMethod]\n  dt[is.na(dt$new)]$new <- 0.5\n  return(dt$new)\n}\n\n# return per color\nreturn_per_color <- function(dt){\n  dt[, new := mean(returnQuantity,na.rm=TRUE), by = colorCode]\n  dt[is.na(dt$new)]$new <- 0.5\n  return(dt$new)\n}\n\n\n#############################################\n#                                           #\n#    7. FUNCTIONS FOR ENSEMBLE SELECTION    #\n#                                           #\n#############################################\n\n# There are two functions: \n# 1) ES performs simple Ensemble Selection.\n# 2) BES performs Bagged Ensemble Selection.\n\n# loading library\nlibrary(compiler)\n\n# function for perfroming ES\nES <- cmpfun(function(X, Y, iter = 100L){\n  \n  # setting initial values\n  N           <- ncol(X)\n  weights     <- rep(0L, N)\n  pred        <- 0 * X\n  sum.weights <- 0L\n  \n  # performing hill-climbing\n  while(sum.weights < iter) {\n    sum.weights   <- sum.weights + 1L\n    pred          <- (pred + X) * (1L / sum.weights)\n    errors        <- sqrt(colSums((pred - Y) ^ 2L))\n    best          <- which.min(errors)\n    weights[best] <- weights[best] + 1L\n    pred          <- pred[, best] * sum.weights\n  }\n  \n  # returning model weights\n  return(weights / sum.weights)\n})\n\n\n# function for performing bagged ES\nBES <- cmpfun(function(X, Y, bags = 10L, p = 0.5, iter = 100L, display = TRUE){\n  \n  # setting initial values\n  i <- 0L\n  N <- nrow(X)\n  M <- ncol(X)\n  W <- matrix(rbinom(bags * M, 1, p), ncol = M)\n  \n  # performing bagging\n  while(i < bags)  {\n    \n    # displyaing iteration number  \n    if ((display == TRUE) & ((i+1)%%10L == 0L)) {\n      print(paste0(\"BES - iteration \", i+1, \"/\", bags))\n    }\n    \n    # doing ES on a bagged sample\n    i         <- i + 1L\n    ind       <- which(W[i, ] == 1)\n    W[i, ind] <- W[i, ind] * ES(X[, ind], Y, iter)\n  }\n  \n  # returning model weights\n  return(colSums(W) / bags)\n})\n\n\n#############################################\n#                                           #\n#      8. FUNCTION FOR PARALLELIZATION      #\n#                                           #\n#############################################\n\n# function for combining results of parallel processes into lists\ncomb <- function(x, ...) {\n  lapply(seq_along(x), function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))\n}\n\n\n#############################################\n#                                           #\n#      9. FUNCTION FOR DATA PARTITIONING    #\n#                                           #\n#############################################\n\n#Function:\nselectPart<- function(tr, part, colNum, cat){\n  dataset<- tr[tr$unique_ID %in% part$unique_ID[part[,colNum]==cat],]\n  return(dataset)\n}",
    "created" : 1540214109101.000,
    "dirty" : false,
    "encoding" : "ISO8859-1",
    "folds" : "",
    "hash" : "3148150674",
    "id" : "B9DE7D89",
    "lastKnownWriteTime" : 1463221376,
    "last_content_update" : 1463221376,
    "path" : "C:/Users/Lara/One Drive - Warwick/OneDrive - University of Warwick/GeneticAgorithm/code/prediction_helper.R",
    "project_path" : "code/prediction_helper.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}